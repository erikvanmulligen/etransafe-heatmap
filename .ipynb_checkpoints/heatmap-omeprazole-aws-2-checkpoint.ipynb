{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eTransafe Omeprazole Heatmap\n",
    "\n",
    "This is the use scenario that has been described in the eTox project for exploring the differences with respect to adverse events between omeprazole preclinical and clinical. In order to compute these results the following scenario is executed:\n",
    "1. Translate the provided compound (e.g., omeprazole) to a SMILES\n",
    "2. Retrieve similar compounds based on structural similarity\n",
    "3. Retrieve data from the preclinical and clinical databases\n",
    "4. Aggregate the data per system organ class\n",
    "5. Visualize the data using a heatmap\n",
    "\n",
    "(C) 2021 Erasmus University Medical Center, Rotterdam, The Netherlands\n",
    "Author: Erik M. van Mulligen, e.vanmulligen@erasmusmc.nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from kh.api import KnowledgeHubAPI\n",
    "import ipywidgets as w\n",
    "from IPython.display import display, Javascript\n",
    "from ipypublish import nb_setup\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import seaborn as sns\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KnowledgeHubAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Translate compound to SMILES using semantic services\n",
    "For the entered compound name, retrieve the associated SMILES using the semantic services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compoundName = w.Text(value='omeprazole',placeholder='compound name', description='compound:', disabled=False)\n",
    "compoundBtn = w.Button(description='Retrieve')\n",
    "compoundSmile = None\n",
    "\n",
    "def on_compound_entered(_):\n",
    "        compound = api.SemanticService().normalize(compoundName.value, ['RxNorm','smiles'])\n",
    "        if 'concepts' in compound:\n",
    "            for concept in compound['concepts']:\n",
    "                if 'vocabularyId' in concept:\n",
    "                    if concept['vocabularyId'] == 'smiles':\n",
    "                        global compoundSmile\n",
    "                        compoundSmile = concept['conceptCode']\n",
    "                        print(f'Found SMILES {compoundSmile} for {compoundName.value}')\n",
    "                        display(Javascript('IPython.notebook.execute_cell_range(IPython.notebook.get_selected_index()+1, IPython.notebook.get_selected_index()+2)'))\n",
    "\n",
    "compoundBtn.on_click(on_compound_entered) \n",
    "w.VBox([compoundName, compoundBtn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compoundIds = []\n",
    "compoundNames = []\n",
    "names = []\n",
    "smiles = []\n",
    "similarities = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve similar compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_compounds = api.SimilarityService().get(compoundSmile, nr_results = 20)\n",
    "\n",
    "if similar_compounds != None:\n",
    "    if ('search_results' in similar_compounds) and (len(similar_compounds['search_results']) == 1):\n",
    "        search_result = similar_compounds['search_results'][0]\n",
    "        if 'obj_nam' in search_result:\n",
    "            for i in range(len(search_result['obj_nam'])):\n",
    "                names.append(search_result['obj_nam'][i])\n",
    "                smiles.append(search_result['SMILES'][i])\n",
    "                similarities.append(\"{:.4f}\".format(search_result['distances'][i]))\n",
    "\n",
    "            for cmp in search_result['obj_nam']:\n",
    "                concept = api.SemanticService().normalize(cmp, ['RxNorm'])\n",
    "                if 'concepts' in concept and len(concept['concepts']) == 1:\n",
    "                    compoundIds.append(concept['concepts'][0]['conceptCode'])\n",
    "                    compoundNames.append(concept['concepts'][0]['conceptName'])\n",
    "        else:\n",
    "            print('something wrong in the result object from the similarity service')    \n",
    "\n",
    "pd = nb_setup.setup_pandas(escape_latex=False)\n",
    "df = pd.DataFrame(np.random.rand(len(names),3),columns=['NAME','SMILES','SIMILARITY'])\n",
    "df.NAME = names\n",
    "df.SMILES = smiles\n",
    "df.SIMILARITY = similarities\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retrieve data from the preclinical and clinical databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = {\n",
    "    'Medline': api.Medline().getStudiesByCompoundIds(compoundIds),\n",
    "    'FAERS': api.Faers().getStudiesByCompoundIds(compoundIds),\n",
    "    'ClinicalTrials': api.ClinicalTrials().getStudiesByCompoundIds(compoundIds),\n",
    "    'eTOXSys': api.eToxSys().getStudiesByCompoundNames(compoundNames)\n",
    "}\n",
    "\n",
    "count = 0\n",
    "for source in studies:\n",
    "    count += len(studies[source])\n",
    "print(f'Found {count} studies.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Aggregate the data per system organ class\n",
    "\n",
    "Since the eTox data reports events with an organ. We use our own method to map it to MedDRA's system organ class to make it comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = {}\n",
    "all_compounds = [c.lower() for c in compoundNames]\n",
    "socs = {}\n",
    "socs_labels = []\n",
    "\n",
    "# retrieve all system organ classes used\n",
    "for source in studies:\n",
    "    for study in studies[source]:\n",
    "        if study['FINDING']['finding'] != None and study['FINDING']['finding'] != 'No abnormalities detected' and len(study['FINDING']['finding']) > 0:\n",
    "            specimenOrgans = api.SemanticService().getSocs(study['FINDING']['specimenOrgan'])\n",
    "            for specimenOrgan in specimenOrgans:\n",
    "                if len(specimenOrgan) > 0:\n",
    "                    if specimenOrgan not in socs:\n",
    "                        socs[specimenOrgan] = 0\n",
    "                        socs_labels.append(specimenOrgan)\n",
    "\n",
    "# travers the studies and count distinct findings per system organ class\n",
    "for source in studies:\n",
    "    # initialize for each source again a data structure to capture per combination of a system organ class \n",
    "    # and a compound what findings have been found\n",
    "    findings_rows_cols = [[[] for compound in all_compounds] for soc in socs_labels]\n",
    "        \n",
    "    for study in studies[source]:\n",
    "        if study['FINDING']['finding'] != None and study['FINDING']['finding'] != 'No abnormalities detected' and len(study['FINDING']['finding']) > 0:\n",
    "            specimenOrgans = api.SemanticService().getSocs(study['FINDING']['specimenOrgan'])\n",
    "            for specimenOrgan in specimenOrgans:\n",
    "                if len(specimenOrgan) > 0:\n",
    "                    compound = study['COMPOUND']['name'].lower()\n",
    "                    row = socs_labels.index(specimenOrgan)\n",
    "                    col = all_compounds.index(compound)\n",
    "                    finding = study['FINDING']['finding']\n",
    "                    if finding not in findings_rows_cols[row][col]:\n",
    "                        socs[specimenOrgan] += 1\n",
    "                        findings_rows_cols[row][col].append(finding)\n",
    "          \n",
    "# sort the socs per count\n",
    "all_socs = {k: v for k, v in sorted(socs.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# traverse all studies and create a matrix per source\n",
    "for source in studies:\n",
    "    system[source] = {\n",
    "        'data':np.zeros((len(all_socs),len(all_compounds)), dtype=int).tolist(), \n",
    "        'rows':list(all_socs.keys()), \n",
    "        'cols':all_compounds\n",
    "    }\n",
    "\n",
    "    # initialize for each source again a data structure to capture per combination of a system organ class \n",
    "    # and a compound what findings have been found\n",
    "    findings_rows_cols = [[[] for compound in all_compounds] for soc in socs_labels]\n",
    "        \n",
    "    for study in studies[source]:\n",
    "        if study['FINDING']['finding'] != None and study['FINDING']['finding'] != 'No abnormalities detected' and len(study['FINDING']['finding']) > 0:\n",
    "            specimenOrgans = api.SemanticService().getSocs(study['FINDING']['specimenOrgan'])\n",
    "            for specimenOrgan in specimenOrgans:\n",
    "                if len(specimenOrgan) > 0:\n",
    "                    row = system[source]['rows'].index(specimenOrgan)\n",
    "                    col = system[source]['cols'].index(study['COMPOUND']['name'].lower())\n",
    "                    finding = study['FINDING']['finding']\n",
    "                    if finding not in findings_rows_cols[row][col]:\n",
    "                        system[source]['data'][row][col] += 1\n",
    "                        findings_rows_cols[row][col].append(finding)\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualize the data using a heatmap\n",
    "\n",
    "Using seaborn to visualize the content of the various databases. Note that we have to think about ways to easier compare the various results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for source,value in system.items():\n",
    "    plt.figure(figsize=(12,9))\n",
    "    data = system[source]['data']\n",
    "    \n",
    "    # create mask\n",
    "    data_mask = ma.array(np.zeros((len(all_socs.keys()), len(all_compounds))))\n",
    "    for r in range(0, len(all_socs.keys())):\n",
    "        for c in range(0, len(all_compounds)):\n",
    "            data_mask[r][c] = 1 if data[r][c] == 0 else 0\n",
    "\n",
    "    colormap = sns.cubehelix_palette(as_cmap=True, light=.9)\n",
    "    ax = sns.heatmap(data, mask=data_mask, xticklabels=all_compounds, yticklabels=list(all_socs.keys()), annot=True, fmt=\".0f\", cmap=colormap) \n",
    "    ax.set_xticklabels(ax.get_xmajorticklabels(), rotation=45)\n",
    "    plt.title(source, fontsize = 14)\n",
    "    plt.ylabel(\"Findings per organ class\", fontsize = 12)\n",
    "    plt.xlabel(\"Similar compounds\", fontsize = 12)\n",
    "    plt.show()\n",
    "\n",
    "    i += 1\n",
    "    print('')\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (KnowledgeHub)",
   "language": "python",
   "name": "pycharm-98e22f02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
